{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass as data\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "#from DataExtraction import p2E2 as data\n",
    "from DataExtraction import e2P2Dec \n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.73596191  0.8398658  -0.11143488 39.48083318]\n",
      "[47.30611801  1.31948066 -0.59230787 94.81924115]\n",
      "[151.81565857   0.9477132   -0.26961038 225.25115398]\n",
      "[335.43484497  -0.39157015   0.69631833 361.48074898]\n",
      "[32.45707321 -0.29633594  2.52936745 33.89280616]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16644512e-04  3.68381017e-03 -3.08543208e-04  8.88321225e-05]\n",
      "[ 0.00019202  0.00578749 -0.00163999  0.00021334]\n",
      "[ 0.00061625  0.00415685 -0.0007465   0.00050682]\n",
      "[ 0.00136159 -0.0017175   0.00192798  0.00081333]\n",
      "[ 1.31749181e-04 -1.29978543e-03  7.00336480e-03  7.62590266e-05]\n"
     ]
    }
   ],
   "source": [
    "#Normalize train data\n",
    "train_data[:,0] = train_data[:,0] / np.linalg.norm(train_data[:,0]) # normalize column 0\n",
    "train_data[:,1] = train_data[:,1] / np.linalg.norm(train_data[:,1]) # normalize column 1\n",
    "train_data[:,2] = train_data[:,2] / np.linalg.norm(train_data[:,2]) # normalize column 2\n",
    "train_data[:,3] = train_data[:,3] / np.linalg.norm(train_data[:,3]) # normalize column 3\n",
    "#Normalize test data\n",
    "test_data[:,0] = test_data[:,0] / np.linalg.norm(test_data[:,0]) # normalize column 0\n",
    "test_data[:,1] = test_data[:,1] / np.linalg.norm(test_data[:,1]) # normalize column 1\n",
    "test_data[:,2] = test_data[:,2] / np.linalg.norm(test_data[:,2]) # normalize column 2\n",
    "test_data[:,3] = test_data[:,3] / np.linalg.norm(test_data[:,3]) # normalize column 3\n",
    "\n",
    "for i in range(5):\n",
    "    print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old data normalization\n",
    "# train_data = train_data/avgE2\n",
    "# test_data = test_data/avgE2\n",
    "# X = train_data\n",
    "# test_data\n",
    "# for i in range(5): \n",
    "#     print(train_data[i])\n",
    "# print(\"bruh\")\n",
    "# for i in range(5): \n",
    "#     print(test_data[i])\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16644512e-04  3.68381017e-03 -3.08543208e-04  8.88321225e-05]\n",
      "[ 0.00019202  0.00578749 -0.00163999  0.00021334]\n",
      "[ 0.00061625  0.00415685 -0.0007465   0.00050682]\n",
      "[ 0.00136159 -0.0017175   0.00192798  0.00081333]\n",
      "[ 1.31749181e-04 -1.29978543e-03  7.00336480e-03  7.62590266e-05]\n",
      "[ 0.00031031  0.00759723 -0.00505055  0.00041595]\n",
      "[ 0.00029495 -0.0034448  -0.00836765  0.00017956]\n",
      "[ 0.00127943 -0.00695786 -0.00485524  0.00149743]\n",
      "[0.00053175 0.00303463 0.0036477  0.00030524]\n",
      "[ 0.00059107  0.00370992 -0.00591427  0.00037477]\n"
     ]
    }
   ],
   "source": [
    "# take first two columns of data\n",
    "# train_data = train_data[:,0:2]\n",
    "# test_data = test_data[:,0:2]\n",
    "# train_labels = train_labels[0:9]\n",
    "for i in range(5):\n",
    "    print(train_data[i])\n",
    "for i in range(5):\n",
    "    print(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define all our functions\n",
    "\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# loss functions\n",
    "def softmax_loss(y,y_hat):\n",
    "    # Clipping value\n",
    "    minval = 0.000000000001\n",
    "    # Number of samples\n",
    "    m = y.shape[0]\n",
    "    # Loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula\n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    #loss = -1/m * np.sum(y * np.log(y_hat))\n",
    "    return loss\n",
    "\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n",
    "    \n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n",
    "\n",
    "# This is the forward propagation function\n",
    "def forward_prop(model,a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    #Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3}\n",
    "    return cache\n",
    "\n",
    "# This is the BACKWARD PROPAGATION function\n",
    "def backward_prop(model,cache,y):\n",
    "\n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'],model['W3'],model['b3']\n",
    "    # Load forward propagation results\n",
    "    a0,a1, a2,a3 = cache['a0'],cache['a1'],cache['a2'],cache['a3']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz3 = loss_derivative(y=y,y_hat=a3)\n",
    "\n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*(a2.T).dot(dz3) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n",
    "\n",
    "#TRAINING PHASE\n",
    "def initialize_parameters(nn_input_dim,nn_hdim,nn_output_dim):\n",
    "    # First layer weights\n",
    "    W1 = 2 *np.random.randn(nn_input_dim, nn_hdim) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = 2 * np.random.randn(nn_hdim, nn_hdim) - 1\n",
    "    \n",
    "    # Second layer bias\n",
    "    b2 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Third layer weights\n",
    "    W3 = 2 * np.random.rand(nn_hdim, nn_output_dim) - 1\n",
    "    \n",
    "    # Third layer bias\n",
    "    b3 = np.zeros((1,nn_output_dim))\n",
    "    \n",
    "    \n",
    "    # Package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model,grads,learning_rate):\n",
    "    # Load parameters\n",
    "    W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "    \n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    \n",
    "    # Store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3':W3,'b3':b3}\n",
    "    return model\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a3']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a3 = cache['a3']\n",
    "        thisLoss = mse_loss(y_,a3) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a3,train_labels)\n",
    "        train_accuracies.append(accur)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a3, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model\n",
    "\n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i][0]>.5:\n",
    "            _outputNodes[i]=[1,0]\n",
    "        else:\n",
    "            _outputNodes[i]=[0,1]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.5023226841946036\n",
      "Train Accuracy after iteration 0 : 50.13021162549619 %\n",
      "Test Accuracy after iteration 0 : 49.48800283178681 %\n",
      "Loss after iteration 300 : 0.5021950462363546\n",
      "Train Accuracy after iteration 300 : 50.19342115243609 %\n",
      "Test Accuracy after iteration 300 : 49.51075826148517 %\n",
      "Loss after iteration 600 : 0.50208558989401\n",
      "Train Accuracy after iteration 600 : 50.07964400394428 %\n",
      "Test Accuracy after iteration 600 : 49.57649616950267 %\n",
      "Loss after iteration 900 : 0.5019899128320727\n",
      "Train Accuracy after iteration 900 : 50.09987105256505 %\n",
      "Test Accuracy after iteration 900 : 49.54362721549392 %\n",
      "Loss after iteration 1200 : 0.5019049810409908\n",
      "Train Accuracy after iteration 1200 : 50.089757528254665 %\n",
      "Test Accuracy after iteration 1200 : 49.495587975019596 %\n",
      "Loss after iteration 1500 : 0.5018278000594087\n",
      "Train Accuracy after iteration 1500 : 50.17572248489293 %\n",
      "Test Accuracy after iteration 1500 : 49.470304164243636 %\n",
      "Loss after iteration 1800 : 0.501755178278372\n",
      "Train Accuracy after iteration 1800 : 50.125154863341 %\n",
      "Test Accuracy after iteration 1800 : 49.515815023640364 %\n",
      "Loss after iteration 2100 : 0.5016836497791717\n",
      "Train Accuracy after iteration 2100 : 50.13526838765139 %\n",
      "Test Accuracy after iteration 2100 : 49.57396778842507 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(nn_input_dim=4, nn_hdim= 7, nn_output_dim= 2)\n",
    "model = train(model,train_data,train_labels,learning_rate=0.01,epochs=2101,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch (Pt Eta Phi E)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight 1: \n",
      " [[ 2.53026927 -0.1968927   0.95974309  3.4810478   2.73580919 -2.95557404\n",
      "   0.90156696]\n",
      " [-1.27475437 -1.17582482 -0.1557902  -0.72219813  1.91615124  0.50721257\n",
      "  -0.73923345]\n",
      " [-0.10513992 -0.32492891  1.99393077 -1.41298024 -0.37198982 -2.71200616\n",
      "  -6.10163815]\n",
      " [ 0.30995339  0.73221914 -2.48156011  3.53864539 -3.90786395 -0.90973707\n",
      "  -1.3726944 ]]\n",
      "Weight 2: \n",
      " [[ 2.06159457  1.933253   -0.69281089 -0.2422982  -2.77341459 -4.96185842\n",
      "  -1.69100707]\n",
      " [-0.69166991  1.45431467  1.4017052  -1.77310289 -1.60215465 -3.09741453\n",
      "  -3.83457137]\n",
      " [-4.41185792  2.90234324 -2.0188931  -1.87634432 -3.50579881  0.55498297\n",
      "  -4.2285165 ]\n",
      " [-1.42738649 -2.79322588 -0.22732654 -2.02106425 -3.36047305 -1.05642537\n",
      "  -0.14136294]\n",
      " [-0.86100432 -0.38657103 -2.26450577 -1.72759296 -2.34813779 -1.71869788\n",
      "  -2.63374359]\n",
      " [-4.45420636 -0.6479155  -1.80482929 -4.25978503 -0.07331854 -2.81473071\n",
      "  -0.89386908]\n",
      " [ 0.44980228 -0.75437501  1.27289635 -3.46670074 -0.19041399 -2.37019922\n",
      "  -2.73110157]]\n",
      "Weight 3: \n",
      " [[ 0.16875762 -0.95551666]\n",
      " [ 0.6544231  -0.98715209]\n",
      " [ 0.33481353 -0.43916451]\n",
      " [ 0.50429898  0.89046616]\n",
      " [-0.49557045  0.14539141]\n",
      " [ 0.2262419   0.10234577]\n",
      " [-0.52587878  0.87754007]]\n",
      "Bias 1: \n",
      " [[ 0.00326059 -0.00100269 -0.01166814 -0.00555057 -0.00884737 -0.01567643\n",
      "  -0.0043978 ]]\n",
      "Bias 2: \n",
      " [[ 1.43392349e-03  1.04849739e-03  1.87580725e-03  1.19465376e-03\n",
      "  -5.76544741e-04 -5.55350719e-05  7.98855207e-04]]\n",
      "Bias 3: \n",
      " [[ 0.0033427 -0.0033427]]\n",
      "2.530269273103178,-0.1968926965980521,0.9597430920105126,3.481047797924231,2.735809185823563,-2.9555740372057357,-1.2747543729775053,-1.175824819077599,-0.1557902018354657,-0.722198128073589,1.9161512354287402,0.5072125696124262,-0.10513991896791647,-0.32492891245083405,1.9939307708630083,-1.412980239111455,-0.3719898161255665,-2.712006157576417,0.30995339018256873,0.7322191353806315,-2.4815601083152474,3.538645392001366,-3.907863948684818,-0.9097370678631455,"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-381f552223ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# file = open(\"weights_ptEtaPhiE.txt\",\"w\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "#print(model)\n",
    "#np.savetxt(\"weights_ptEtaPhi.csv\", model, delimiter=\",\")\n",
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "print(\"Weight 1: \\n\", W1)\n",
    "print(\"Weight 2: \\n\", W2)\n",
    "print(\"Weight 3: \\n\", W3)\n",
    "print(\"Bias 1: \\n\", b1)\n",
    "print(\"Bias 2: \\n\", b2)\n",
    "print(\"Bias 3: \\n\", b3)\n",
    "\n",
    "b1=b1[0].tolist()\n",
    "\n",
    "# file = open(\"weights_ptEtaPhiE.txt\",\"w\") \n",
    "for i in range (len(b1)-1):\n",
    "    W = W1[i].tolist()\n",
    "    for j in range(len(W)-1):\n",
    "        print(W[j],end=\",\")\n",
    "# file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    print(test_data[i])\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get weights and biases\n",
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "\n",
    "diffArray = []\n",
    "\n",
    "plotX = []\n",
    "plotY = []\n",
    "\n",
    "inputArr = []\n",
    "outputArr = []\n",
    "for i in range(len(test_data)-1):\n",
    "    _a0 = test_data[i]\n",
    "    #print(_a0, _a0[1]-_a0[0])\n",
    "    diffArray.append(_a0[1]-_a0[0])\n",
    "    inputArr.append(_a0[1])\n",
    "    _z1 = _a0.dot(W1) + b1\n",
    "    # Put it through the first activation function\n",
    "    _a1 = np.tanh(_z1)\n",
    "    # Second linear step\n",
    "    _z2 = _a1.dot(W2) + b2\n",
    "    # Second activation function\n",
    "    _a2 = np.tanh(_z2)\n",
    "    #Third linear step\n",
    "    _z3 = _a2.dot(W3) + b3\n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    _a3 = softmax(_z3)\n",
    "#     if(i<10):\n",
    "#         print(_a3)\n",
    "    plotX.append(_a3[0][0])\n",
    "    plotY.append(_a3[0][1])\n",
    "plt.scatter(plotX, plotY)\n",
    "    # Calculate the point density\n",
    "#     xy = np.vstack([plotX,plotY])\n",
    "#     z = gaussian_kde(xy)(xy)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "#     plt.show()\n",
    "\n",
    "#plt.hist(diffArray, bins=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot muons, this doesn't work right now and we have no idea why\n",
    "muonX = [] # value of \"muon\" output node\n",
    "muonY = [] # value of \"electron\" output node\n",
    "mCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==1:\n",
    "        mCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y)or x<0 or y<0)!=True:\n",
    "            muonX.append(x)\n",
    "            muonY.append(y)\n",
    "print(mCount-len(muonX), \"lost muons\")\n",
    "# Calculate the point density\n",
    "muon_xy = np.vstack([muonX,muonY])\n",
    "muon_z = gaussian_kde(muon_xy)(muon_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(muonX, muonY, c=muon_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Muons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()\n",
    "#plt.scatter(muonX, muonY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot electrons\n",
    "eleX = [] # value of \"muon\" output node\n",
    "eleY = [] # value of \"electron\" output node\n",
    "eCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==0:\n",
    "        eCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y) or x<0 or y<0)!=True:\n",
    "            eleX.append(x)\n",
    "            eleY.append(y)\n",
    "print(eCount-len(eleX), \"lost electrons\")\n",
    "# Calculate the point density\n",
    "ele_xy = np.vstack([eleX,eleY])\n",
    "ele_z = gaussian_kde(ele_xy)(ele_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(eleX, eleY, c=ele_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Electrons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffArr = []\n",
    "discardedVals = 0\n",
    "for x, y in zip(plotX, plotY):\n",
    "    if(abs(y-x)<.75):\n",
    "        diffArr.append(y-x)\n",
    "    else:\n",
    "        discardedVals += 1\n",
    "print(discardedVals, \"differences greater than .75\")\n",
    "plt.hist(diffArr, bins=1000)\n",
    "plt.title(\"Difference in Electron and Muon Output Node Values (E-M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some models with different numbers of epochs\n",
    "print(\"model 200\")\n",
    "model_200 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_200 = train(model_200,train_data,train_labels,learning_rate=0.01,epochs=201,print_loss=True)\n",
    "# model_300 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_300 = train(model_300,train_data,train_labels,learning_rate=0.01,epochs=301,print_loss=True)\n",
    "print(\"model 400\")\n",
    "model_400 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_400 = train(model_400,train_data,train_labels,learning_rate=0.01,epochs=401,print_loss=True)\n",
    "# model_500 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_500 = train(model_500,train_data,train_labels,learning_rate=0.01,epochs=501,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 200 accuracy: \", accuracyOfModel(model_200, test_data, test_labels))\n",
    "print(\"Model 400 accuracy: \", accuracyOfModel(model_400, test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
