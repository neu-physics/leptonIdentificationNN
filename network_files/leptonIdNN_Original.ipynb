{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib is a matlab like plotting library\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# SciKitLearn is a useful machine learning utilities library\n",
    "import sklearn\n",
    "# The sklearn dataset module helps generating |datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "# import data\n",
    "from DataExtraction import dataNoMass\n",
    "from DataExtraction import dataWithP2\n",
    "from DataExtraction import dataWithP2E2 \n",
    "from DataExtraction import dataWithMass \n",
    "#from DataExtraction import p2E2 as data\n",
    "from DataExtraction import e2P2Dec as data\n",
    "#from DataExtraction import labels\n",
    "from DataExtraction import labels2D as labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size=0.5, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y = train_labels\n",
    "# for i in range(5):\n",
    "#     print(y[i])\n",
    "# print(len(y))\n",
    "# print(y.shape)\n",
    "# x = train_data\n",
    "# for i in range(5):\n",
    "#     print(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runSum = 0\n",
    "for e in train_data:\n",
    "    runSum+=e\n",
    "avgE2 = runSum/(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/avgE2\n",
    "test_data = test_data/avgE2\n",
    "# X = train_data\n",
    "# test_data\n",
    "# for i in range(5): \n",
    "#     print(train_data[i])\n",
    "# print(\"bruh\")\n",
    "# for i in range(5): \n",
    "#     print(test_data[i])\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messing with thenumber of training data points\n",
    "train_data = train_data[0:9]\n",
    "train_labels = train_labels[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we define all our functions\n",
    "\n",
    "def softmax(z):\n",
    "    #Calculate exponent term first\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# loss functions\n",
    "def softmax_loss(y,y_hat):\n",
    "    # Clipping value\n",
    "    minval = 0.000000000001\n",
    "    # Number of samples\n",
    "    m = y.shape[0]\n",
    "    # Loss formula, note that np.sum sums up the entire matrix and therefore does the job of two sums from the formula\n",
    "    loss = -1/m * np.sum(y * np.log(y_hat.clip(min=minval)))\n",
    "    #loss = -1/m * np.sum(y * np.log(y_hat))\n",
    "    return loss\n",
    "\n",
    "def crossEntropy_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    if y.all() == 1:\n",
    "        return -1/m * np.sum(np.log(y_hat))\n",
    "    else:\n",
    "        return -1/m * np.sum(np.log(1 - y_hat))\n",
    "\n",
    "def mse_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    return np.sum((y_hat - y)**2) / m\n",
    "    \n",
    "def loss_derivative(y,y_hat):\n",
    "    return (y_hat-y)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return (1 - np.power(x, 2))\n",
    "\n",
    "# This is the forward propagation function\n",
    "def forward_prop(model,a0):\n",
    "    \n",
    "    #Start Forward Propagation\n",
    "    \n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'], model['W3'],model['b3']\n",
    "    \n",
    "    # Do the first Linear step \n",
    "    # Z1 is the input layer x times the dot product of the weights + our bias b\n",
    "    z1 = a0.dot(W1) + b1\n",
    "    \n",
    "    # Put it through the first activation function\n",
    "    a1 = np.tanh(z1)\n",
    "    \n",
    "    # Second linear step\n",
    "    z2 = a1.dot(W2) + b2\n",
    "    \n",
    "    # Second activation function\n",
    "    a2 = np.tanh(z2)\n",
    "    \n",
    "    #Third linear step\n",
    "    z3 = a2.dot(W3) + b3\n",
    "    \n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    #Store all results in these values\n",
    "    cache = {'a0':a0,'z1':z1,'a1':a1,'z2':z2,'a2':a2,'a3':a3,'z3':z3}\n",
    "    return cache\n",
    "\n",
    "# This is the BACKWARD PROPAGATION function\n",
    "def backward_prop(model,cache,y):\n",
    "\n",
    "    # Load parameters from model\n",
    "    W1, b1, W2, b2, W3, b3 = model['W1'], model['b1'], model['W2'], model['b2'],model['W3'],model['b3']\n",
    "    # Load forward propagation results\n",
    "    a0,a1, a2,a3 = cache['a0'],cache['a1'],cache['a2'],cache['a3']\n",
    "    \n",
    "    # Get number of samples\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    # Calculate loss derivative with respect to output\n",
    "    dz3 = loss_derivative(y=y,y_hat=a3)\n",
    "\n",
    "    # Calculate loss derivative with respect to second layer weights\n",
    "    dW3 = 1/m*(a2.T).dot(dz3) #dW2 = 1/m*(a1.T).dot(dz2) \n",
    "    \n",
    "    # Calculate loss derivative with respect to second layer bias\n",
    "    db3 = 1/m*np.sum(dz3, axis=0)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer\n",
    "    dz2 = np.multiply(dz3.dot(W3.T) ,tanh_derivative(a2))\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer weights\n",
    "    dW2 = 1/m*np.dot(a1.T, dz2)\n",
    "    \n",
    "    # Calculate loss derivative with respect to first layer bias\n",
    "    db2 = 1/m*np.sum(dz2, axis=0)\n",
    "    \n",
    "    dz1 = np.multiply(dz2.dot(W2.T),tanh_derivative(a1))\n",
    "    \n",
    "    dW1 = 1/m*np.dot(a0.T,dz1)\n",
    "    \n",
    "    db1 = 1/m*np.sum(dz1,axis=0)\n",
    "    \n",
    "    # Store gradients\n",
    "    grads = {'dW3':dW3, 'db3':db3, 'dW2':dW2,'db2':db2,'dW1':dW1,'db1':db1}\n",
    "    return grads\n",
    "\n",
    "#TRAINING PHASE\n",
    "def initialize_parameters(nn_input_dim,nn_hdim,nn_output_dim):\n",
    "    # First layer weights\n",
    "    W1 = 2 *np.random.randn(nn_input_dim, nn_hdim) - 1\n",
    "    \n",
    "    # First layer bias\n",
    "    b1 = np.zeros((1, nn_hdim))\n",
    "    \n",
    "    # Second layer weights\n",
    "    W2 = 2 * np.random.randn(nn_hdim, nn_hdim) - 1\n",
    "    \n",
    "    # Second layer bias\n",
    "    b2 = np.zeros((1, nn_hdim))\n",
    "    W3 = 2 * np.random.rand(nn_hdim, nn_output_dim) - 1\n",
    "    b3 = np.zeros((1,nn_output_dim))\n",
    "    \n",
    "    \n",
    "    # Package and return model\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2,'W3':W3,'b3':b3}\n",
    "    return model\n",
    "\n",
    "def update_parameters(model,grads,learning_rate):\n",
    "    # Load parameters\n",
    "    W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "    \n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * grads['dW1']\n",
    "    b1 -= learning_rate * grads['db1']\n",
    "    W2 -= learning_rate * grads['dW2']\n",
    "    b2 -= learning_rate * grads['db2']\n",
    "    W3 -= learning_rate * grads['dW3']\n",
    "    b3 -= learning_rate * grads['db3']\n",
    "    \n",
    "    # Store and return parameters\n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3':W3,'b3':b3}\n",
    "    return model\n",
    "def predict(model, x):\n",
    "    # Do forward pass\n",
    "    c = forward_prop(model,x)\n",
    "    #get y_hat\n",
    "    y_hat = c['a3']\n",
    "    # plotArr.append([x, y_hat]) #added to make plot\n",
    "    return y_hat\n",
    "def calc_accuracy(model,x,y):\n",
    "    # Get total number of examples\n",
    "    m = y.shape[0]\n",
    "    # Do a prediction with the model\n",
    "    pred = predict(model,x)\n",
    "    # Ensure prediction and truth vector y have the same shape\n",
    "    pred = pred.reshape(y.shape)\n",
    "    # Calculate the number of wrong examples\n",
    "    error = np.sum(np.abs(pred-y))\n",
    "    # Calculate accuracy\n",
    "    return (m - error)/m * 100\n",
    "def train(model,X_,y_,learning_rate, epochs=2001, print_loss=False):\n",
    "    # Gradient descent. Loop over epochs\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        # Forward propagation\n",
    "        cache = forward_prop(model,X_)\n",
    "        #a1, probs = cache['a1'],cache['a2']\n",
    "        # Backpropagation\n",
    "        \n",
    "        grads = backward_prop(model,cache,y_)\n",
    "        # Gradient descent parameter update\n",
    "        # Assign new parameters to the model\n",
    "        model = update_parameters(model=model,grads=grads,learning_rate=learning_rate)\n",
    "    \n",
    "        a3 = cache['a3']\n",
    "        thisLoss = mse_loss(y_,a3) # set loss function here\n",
    "        losses.append(thisLoss)\n",
    "        y_hat = predict(model,X_) # getting rid of this because it's wrong\n",
    "        y_true = y_.argmax(axis=1)\n",
    "        accur = accuracy_score(a3,train_labels)\n",
    "        train_accuracies.append(accur)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            placeholderVar = accuracy_score(a3, train_labels)\n",
    "            test_accuracy = accuracyOfModel(model, test_data, test_labels)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "            test_num.append(i)\n",
    "        #Printing loss & accuracy every 100 iterations\n",
    "        if print_loss and i % 300==0:\n",
    "            print('Loss after iteration',i,':',thisLoss)\n",
    "            print('Train Accuracy after iteration',i,':',accur*100,'%')\n",
    "            print('Test Accuracy after iteration',i,':',test_accuracy*100,'%')\n",
    "    return model\n",
    "\n",
    "# TESTING PHASE\n",
    "# test the accuracy of any model\n",
    "def accuracyOfModel(_model, _testData, _testLabels):\n",
    "    y_pred = predict(_model,_testData) # make predictions on test data\n",
    "    y_true = _testLabels # get usable info from labels\n",
    "    return accuracy_score(y_pred, y_true)\n",
    "\n",
    "def accuracy_score(_outputNodes, _labels):\n",
    "    for i in range(len(_outputNodes)-1):\n",
    "        if _outputNodes[i][0]>.5:\n",
    "            _outputNodes[i]=[1,0]\n",
    "        else:\n",
    "            _outputNodes[i]=[0,1]\n",
    "    numWrong = np.count_nonzero(np.subtract(_outputNodes,_labels))/2\n",
    "    return (len(_outputNodes)-numWrong)/len(_outputNodes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.5580658790693763\n",
      "Train Accuracy after iteration 0 : 66.66666666666666 %\n",
      "Test Accuracy after iteration 0 : 51.022730145887586 %\n",
      "Loss after iteration 300 : 0.4076570218374331\n",
      "Train Accuracy after iteration 300 : 66.66666666666666 %\n",
      "Test Accuracy after iteration 300 : 50.41591868726455 %\n",
      "Loss after iteration 600 : 0.3718006959166338\n",
      "Train Accuracy after iteration 600 : 66.66666666666666 %\n",
      "Test Accuracy after iteration 600 : 50.41591868726455 %\n",
      "Loss after iteration 900 : 0.3146740597674263\n",
      "Train Accuracy after iteration 900 : 66.66666666666666 %\n",
      "Test Accuracy after iteration 900 : 50.362822684635034 %\n",
      "Loss after iteration 1200 : 0.27748729309120435\n",
      "Train Accuracy after iteration 1200 : 77.77777777777779 %\n",
      "Test Accuracy after iteration 1200 : 56.06179363353645 %\n",
      "Loss after iteration 1500 : 0.25617878395634835\n",
      "Train Accuracy after iteration 1500 : 77.77777777777779 %\n",
      "Test Accuracy after iteration 1500 : 53.43986245606938 %\n",
      "Loss after iteration 1800 : 0.2371727063831813\n",
      "Train Accuracy after iteration 1800 : 77.77777777777779 %\n",
      "Test Accuracy after iteration 1800 : 54.55487851128922 %\n",
      "Loss after iteration 2100 : 0.2095785149480615\n",
      "Train Accuracy after iteration 2100 : 77.77777777777779 %\n",
      "Test Accuracy after iteration 2100 : 59.7684002932922 %\n"
     ]
    }
   ],
   "source": [
    "# plotArr = []\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "test_num = []\n",
    "np.random.seed(0)\n",
    "# This is what we return at the end\n",
    "model = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model = train(model,train_data,train_labels,learning_rate=0.01,epochs=2201,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.scatter(test_num, test_accuracies, label=\"Test Accuracy\", s=16, color=\"green\")\n",
    "plt.legend()\n",
    "plt.title(\"Network Loss and Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.75002683 1.75009416]\n",
      "[1.90345077 1.88149124]\n",
      "[0.19035625 0.16807067]\n",
      "[0.49133276 0.49179333]\n",
      "[0.89221778 0.87006578]\n",
      "[0.44086735 0.44105678]\n",
      "[1.98645791 1.96451417]\n",
      "[0.79652026 0.79685403]\n",
      "[1.78614203 1.78704311]\n",
      "[1.84022166 1.81825009]\n",
      "39551\n"
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    print(test_data[i])\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49417117 0.50582883]]\n",
      "[[0.4941951 0.5058049]]\n",
      "[[0.41981008 0.58018992]]\n",
      "[[0.46404521 0.53595479]]\n",
      "[[0.48837292 0.51162708]]\n",
      "[[0.45312376 0.54687624]]\n",
      "[[0.49421506 0.50578494]]\n",
      "[[0.48825276 0.51174724]]\n",
      "[[0.49418517 0.50581483]]\n",
      "[[0.49417421 0.50582579]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10e874048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGKJJREFUeJzt3X+M1Pd95/HnywvExIdLWm+iesGGSwjOprjedktcWbr60lIwKLBN7mJoLNVSaqs/SI5zigrCl9jUyNugcxzpOOmIdWoUpwZq+VZUkGx9ta2qVkBsxNoI29hrvAUWKd6mRqlibGD77h8zg4dldue7M9/59Z3XQ1ppvt/5zM5bo+HFZz+fz/fzVURgZmbZck2jCzAzs/Q53M3MMsjhbmaWQQ53M7MMcribmWWQw93MLIMc7mZmGeRwNzPLIIe7mVkGzWrUG99www2xaNGiRr29mVlL+vGPf/zPEdFZrl2icJe0Cvg20AE8ERH9k56/CfguMD/fZktEHJzudy5atIihoaEkb29mZnmS/ilJu7LDMpI6gF3AXUA3sEFS96RmDwL7IqIHWA/875mVa2ZmaUoy5r4cGImIkxFxAdgDrJvUJoDr849/ATibXolmZjZTScK9CzhddHwmf67YQ8A9ks4AB4GvlPpFku6XNCRpaHx8vIJyzcwsibRWy2wA/ioiFgCrge9Juup3R8TuiOiNiN7OzrLzAWZmVqEk4T4GLCw6XpA/V+zLwD6AiPgRcC1wQxoFmpnZzCUJ9yPAEkmLJc0hN2G6f1KbU8BvA0j6FLlw97iLmVmDlA33iLgEbAQGgVfJrYo5Lmm7pLX5Zl8D7pP0EvAUcG/4Fk9mZg2TaJ17fs36wUnnvl70+BXgjnRLMzOzSnn7ATOzDGrY9gNpWLTlQMnzo/1r6lyJmVlzadme+1TBXu45M7N20LLhXo4D3szaWWbDHeCO/ucYODp5Sb6ZWfZlOtzHzp1n6zPHHPBm1nYyHe4A5y9OsHPwRKPLMDOrq5YN95msiDl77nwNKzEzaz4tG+6QPOBvnD+3xpWYmTWXll7nDlcG/MDRMbY+c4zzFycun5s7u4PNK5c2ojQzs4Zp+XAv1teT22Z+5+AJzp47z43z57J55dLL583M2kWmwh1yAe8wN7N219Jj7mZmVprD3cwsgxzuZmYZ5HA3M8sgh7uZWQY53M3MMsjhbmaWQYnCXdIqSSckjUjaUuL5b0kazv+8Lulc+qWamVlSZS9iktQB7AJWAGeAI5L252+KDUBE/Pei9l8BempQq5mZJZSk574cGImIkxFxAdgDrJum/QbgqTSKMzOzyiQJ9y7gdNHxmfy5q0i6GVgMPFd9aWZmVqm0J1TXA09HxESpJyXdL2lI0tD4+HjKb21mZgVJwn0MWFh0vCB/rpT1TDMkExG7I6I3Ino7OzuTV2lmZjOSJNyPAEskLZY0h1yA75/cSNItwEeAH6VbopmZzVTZcI+IS8BGYBB4FdgXEcclbZe0tqjpemBPRERtSjUzs6QS7eceEQeBg5POfX3S8UPplWVmZtXwFapmZhnkcDczyyCHu5lZBjnczcwyyOFuZpZBDnczswxyuJuZZZDD3cwsgxzuZmYZlOgKVWuMBweO8dTh00xE0CGx4TMLeaRvWaPLMrMW4HBvUg8OHOPJQ6cuH09EXD52wJtZOR6WaVJPHT5d8vyTh05xR/9zDBydatdlMzOHe9OamGZzzbFz59n6zDEHvJlNyeHepDqkaZ8/f3GCTXuHWbTlAD3b/85Bb2ZXcLg3qQ2fWVi+Ud47715k89MvOeDN7DKHe5N6pG8Z99x+U9kefMHFiWDn4IkaV2VmrcLh3sQe6VvGm4+u5vG7b2Pu7I6y7c+eO1+HqsysFXgpZAvo6+kCYOfgCcamCfAb58+tV0lm1uTcc28RfT1dvLjlszx+923MvubqoZrZHWLzyqUNqMzMmpF77i2m0It/aP9xzp2/CMBHPjybb3zu05efKxg4OsbOwROcPXeeG+fPZfPKpVe1MbNsShTuklYB3wY6gCcior9Emy8CDwEBvBQRv59inVakr6erbEgPHB1j6zPHOH9xAvhgbXzh9WaWbWWHZSR1ALuAu4BuYIOk7kltlgBbgTsi4tPAphrUajOwc/DE5WAvKKyN97p4s+xLMua+HBiJiJMRcQHYA6yb1OY+YFdEvAMQEW+nW6bN1HQrZ9559yKb9g7zqf/xA4e8WUYlCfcuoHijkzP5c8U+CXxS0ouSDuWHcayBkqycOX/x3y5f5bpoy4E6VGVm9ZLWaplZwBLgTmAD8B1J8yc3knS/pCFJQ+Pj4ym9tZWyeeXSRGvjizngzbIjSbiPAcXXwi/Inyt2BtgfERcj4i3gdXJhf4WI2B0RvRHR29nZWWnNlkBfTxePfn5Z4itcC9yLN8uGJOF+BFgiabGkOcB6YP+kNgPkeu1IuoHcMM3JFOu0CvT1dPE/v/irJdfFl+OQN2ttZcM9Ii4BG4FB4FVgX0Qcl7Rd0tp8s0Hgp5JeAZ4HNkfET2tVtCXX19PFzv/6q3x4dmUjcA54s9akmGbf8Frq7e2NoaGhhrx3uxo4OsamvcMVv360f02K1ZhZJST9OCJ6y7Xz9gNtpK+nq6qAdi/erHU43NtQtQHvkDdrfg73NlXtEIsD3qy5eczdqg5qj8Wb1Y/H3C2x0f41Hos3yxiHu13msXiz7PCwjJXkoRqz5uRhGauKJ1zNWpt77laWe/FmzcM9d0uNe/Fmrcc9d5sR9+LNGss9d6uJ0f41fGzenIpf7168WX24524Vcy/erP6S9twd7lY1h7xZ/XhYxurGE65mzcc9d0uVe/FmteWeuzWEe/FmzcE9d6sZ9+LN0ueeuzWce/FmjeOeu9VFNUF9bYd4bcfqFKsxa12p9twlrZJ0QtKIpC0lnr9X0rik4fzPH1ZStGVXNXvGvzcR7sWbzVDZcJfUAewC7gK6gQ2Suks03RsRt+V/nki5TssI7xlvVh9Jeu7LgZGIOBkRF4A9wLralmVZlsadnx4cOJZiRWbZkyTcu4DTRcdn8ucm+4KklyU9LWlhqV8k6X5JQ5KGxsfHKyjXsqSagH/y0CkWuxdvNqW0Vsv8LbAoIm4FngW+W6pRROyOiN6I6O3s7Ezpra2VVdOLD3K9+Fu2HUy3KLMMSBLuY0BxT3xB/txlEfHTiHg/f/gE8OvplGftoppevCdcza6WJNyPAEskLZY0B1gP7C9uIOmXiw7XAq+mV6K1izTG4m/9xg9TrMisdZUN94i4BGwEBsmF9r6IOC5pu6S1+WZflXRc0kvAV4F7a1WwZV81If+z9yfcizfDFzFZk6smqD82bw6Ht61IsRqzxvP2A5YJ1fTif/KvF9yLt7blcLeWUM3t/RZtOcBndjybckVmzc3hbi3j8LYVVffiB46OlW9slgEOd2s5o/1ruOf2myp67aa9wx6qsbbgcLeW9EjfMkb716AKX79oywFWPPZCmiWZNRWHu7W0t6qYcH3j7Z+7F2+Z5XC3TKj24if34i1rHO6WGdUsm3Qv3rLG4W6Z4z3jzRzullFp7FNj1soc7pZp1V785D3jrVV5bxlrG96nxrLAe8uYTVLNxU/ep8ZajcPd2krh4qfrP9RR0eu9T421Coe7taWXH17l3SYt0xzu1tZG+9cwq8I9DBZtOcAntjrkrTk53K3tjTxa+bLJS+Flk9acHO5medWOxfv+rdZMHO5mRaoZiy/cv/XBgWMpV2U2c4nCXdIqSSckjUjaMk27L0gKSWXXYJo1s9H+NVzbUdlg/JOHTnmoxhqubLhL6gB2AXcB3cAGSd0l2s0D/htwOO0izRrhtR2rq97C4Evf+VGKFZkll6TnvhwYiYiTEXEB2AOsK9HuL4C/BN5LsT6zhqvm4qcX3/wXj8VbQyQJ9y7gdNHxmfy5yyT9GrAwIvy3qGVS4eKnSngs3hqh6glVSdcAjwFfS9D2fklDkobGx8erfWuzuqtmt0mPxVs9JQn3MWBh0fGC/LmCecCvAC9IGgVuB/aXmlSNiN0R0RsRvZ2dnZVXbdZgo/1rWPLR6yp6rcfirR7K7gopaRbwOvDb5EL9CPD7EXF8ivYvAH8WEdNu+ehdIS0rqumN33P7TTzStyzFaizrUtsVMiIuARuBQeBVYF9EHJe0XdLa6ks1a23VXPz05KFT3sLAasL7uZulyL14qzXv527WANUsm/SEq6XJ4W6WssKyyWp2m1zx2Aup1mTtx+FuViMjj67h8btvq+i1b7z9c/firSoOd7Ma6uvpYrR/DXd8/Bcrev2iLQcc8lYRh7tZHXz/vt+sep8as5lwuJvVUbUXPznkLSmHu1mdPfvAnVX34geOjpVvaG3N4W7WINVc/LRp77AvfrJpOdzNGqiaOz8V7t/qfWqsFIe7WRPwnvGWNm8/YNZkqpk0/di8ORzetiLFaqzZePsBsxZVzZ7xP/nXC15RY4DD3axpVbuixkM17c3hbtbEqunFF27vZ+3J4W7WAqqZcPX9W9uTJ1TNWswt2w7y3kRl/269Z3zr84SqWUa9tmN1xbtNes/49uFwN2tBhd0mqxmq8RYG2eZhGbMM+MTWA1yq4J/y9R/q4OWHV6VfkNWMh2XM2sjIo5X14gsrajzhmj2Jwl3SKkknJI1I2lLi+T+SdEzSsKR/lNSdfqlmNp1qbu/35KFTDviMKTssI6kDeB1YAZwBjgAbIuKVojbXR8TP8o/XAn8SEdP+redhGbPaeXDgGE8eOlXRa6/tEK/tWJ1yRZaWNIdllgMjEXEyIi4Ae4B1xQ0KwZ53HdCYgXwzAz7oxVeypfB7E+EVNRmQJNy7gNNFx2fy564g6U8lvQl8E/hqqV8k6X5JQ5KGxsfHK6nXzGbg5YdXVbWi5jM7nk25IquX1CZUI2JXRHwc+HPgwSna7I6I3ojo7ezsTOutzWwahV78x+bNmfFrCxuRrXjshfQLs5pKEu5jwMKi4wX5c1PZA/RVU5SZpe/wthUVX/z0xts/Z7GHalpKknA/AiyRtFjSHGA9sL+4gaQlRYdrgDfSK9HM0lLNxU+B7/zUSsqGe0RcAjYCg8CrwL6IOC5pe35lDMBGScclDQMPAH9Qs4rNrGqFoZolH71uxq/1nZ9ag69QNWtzA0fH2LR3uKLXLvnodTz7wJ3pFmTT8hWqZpZIYaimkmWTHotvXg53MwNyyyYrmXD1WHxzcrib2WWFXnwlyyZffPNfvE9NE3G4m9lVDm9bUfHFT08eOuUJ1ybgcDezkqpZUePdJhvP4W5m03r2gTsZ7V9DBZtN+s5PDeRwN7NE3qpwLB68T00jONzNLLHD21Yw2r+motcW9qmx+nC4m9mMVXv/Vk+41p7D3cwqUs1uk4UJV9+ku3a8/YCZpeKWbQd5b2LmeTJLuXvAWjLefsDM6uq1Hasr2sLgUuBefA043M0sNS8/vKriZZOb9g77piApcribWereqnDC9Y23f+4VNSnxmLuZ1VSlYS1y/0nYlTzmbmZNodItDAq7TXrZZGUc7mZWc4UtDCpRWDZpM+NwN7O6Ge1fwx0f/8WKXute/Mw43M2srr5/328y2r+GaztmvqbGu00mlyjcJa2SdELSiKQtJZ5/QNIrkl6W9PeSbk6/VDPLktd2rK5qz3hvRDa9suEuqQPYBdwFdAMbJHVPanYU6I2IW4GngW+mXaiZZU81WxgUNiLz7f1KS9JzXw6MRMTJiLgA7AHWFTeIiOcj4t384SFgQbplmlmWFXabrOTip8Lt/exKScK9CzhddHwmf24qXwZ+UE1RZtae3upfU9EWBuAJ18lSnVCVdA/QC+yc4vn7JQ1JGhofH0/zrc0sI6rZwsDLJj+QJNzHgIVFxwvy564g6XeAbcDaiHi/1C+KiN0R0RsRvZ2dnZXUa2ZtotItDCDXi//E1vYO+SThfgRYImmxpDnAemB/cQNJPcD/IRfsb6dfppm1o8KEayXLJgu7Tbbrssmy4R4Rl4CNwCDwKrAvIo5L2i5pbb7ZTuA/AH8jaVjS/il+nZnZjFW7bLIdh2q8cZiZtZRbv/FDfvb+xIxfl5WbgnjjMDPLpMKE60xdakw/tmEc7mbWkkarWDbZDhzuZtayKu3FtwOHu5m1vCRbGMyqZOF8C5vV6ALMzNJweNsKoPSdn0pNpg4cHWPn4AnOnjvPjfPnsnnlUvp6prv4vrV4tYyZtZ2Bo2NsfeYY5y9+sOpGwJduv4lH+pY1rrAEvFrGzGwKOwdPXBHskLut3/cPnWLg6FUX4Lckh7uZtZ2z586XPB/Apr3D3NH/XMuHvMPdzNrOjfPnTvv82LnzbNo7TM/2v2vZkHe4m1nb2bxyaaJdJ9959yJbnznWkgHvcDezttPX08WXbr8pUcCfvzjBzsETNa8pbQ53M2tLj/Qt41t330ZXmSEayA3TLN5yoKXG4h3uZta2+nq6eHHLZ3n87tuYO3v6rQyCXMi3yjCNw93M2l5fTxePfn4Z8+fOLtu2VYZpHO5mZuQCfvgbv8vj+aGa6cbjp1pK2Uy8/YCZWZG+nq7L2xDc0f8cYyWCvNxSymbgnruZ2RQ2r1x61Vj83NkdbF65tEEVJeeeu5nZFAo9+FbcYMzhbmY2jeJhmlbiYRkzswxK1HOXtAr4NtABPBER/ZOe/0/A48CtwPqIeDrtQs3MWs0t2w7y3sQH26pf2yFe27G6Lu9dtucuqQPYBdwFdAMbJHVPanYKuBf467QLNDNrRZODHeC9ieCWbQfr8v5Jeu7LgZGIOAkgaQ+wDnil0CAiRvPP/VsNajQzazmTg73c+bQlGXPvAk4XHZ/JnzMzsyZV1wlVSfdLGpI0ND4+Xs+3NjNrK0nCfQxYWHS8IH9uxiJid0T0RkRvZ2dnJb/CzKwlXNtRegODqc6nLUm4HwGWSFosaQ6wHthf27LMzFrbaztWXxXk9VwtU3ZCNSIuSdoIDJJbCvl/I+K4pO3AUETsl/QbwP8DPgJ8TtLDEfHpmlZuZtbk6hXkpSRa5x4RB4GDk859vejxEXLDNWZm1gR8haqZWQY53M3MMsjhbmaWQQ53M7MMcribmWWQw93MLIMc7mZmGeRwNzPLIEXUZ/vJq95YGgf+qejUDcA/N6SYyrVaza1WL7jmemi1eqG9a745IspuztWwcJ9M0lBE9Da6jplotZpbrV5wzfXQavWCa07CwzJmZhnkcDczy6BmCvfdjS6gAq1Wc6vVC665HlqtXnDNZTXNmLuZmaWnmXruZmaWkrqHu6RVkk5IGpG0pcTzD0h6RdLLkv5e0s31rrFETeVq/iNJxyQNS/pHSd2NqLOonmnrLWr3BUkhqeGrDhJ8xvdKGs9/xsOS/rARdRbVU/YzlvTF/Hf5uKS/rneNJeop9xl/q+jzfV3SuUbUOammcjXfJOl5SUfzmdG4u2OQqN6b87n2sqQXJNXuPhgRUbcfcndyehP4j8Ac4CWge1Kb/wx8OP/4j4G99ayxwpqvL3q8FvhhM9ebbzcP+AfgENDbAp/xvcD/amSdM6x3CXAU+Ej++KPNXvOk9l8hd9e1pq6Z3Dj2H+cfdwOjTV7v3wB/kH/8WeB7taqn3j335cBIRJyMiAvAHmBdcYOIeD4i3s0fHqLxd3hKUvPPig6vAxo5kVG23ry/AP4SeK+exU0hac3NIkm99wG7IuIdgIh4u841TjbTz3gD8FRdKptakpoDuD7/+BeAs3Wsb7Ik9XYDz+UfP1/i+dTUO9y7gNNFx2fy56byZeAHNa2ovEQ1S/pTSW8C3wS+WqfaSilbr6RfAxZGxIF6FjaNpN+LL+T/nH1a0sL6lFZSkno/CXxS0ouSDklaVbfqSkv8by8/FLqYD0KoUZLU/BBwj6Qz5G4F+pX6lFZSknpfAj6ff/x7wDxJv1SLYpp2QlXSPUAvsLPRtSQREbsi4uPAnwMPNrqeqUi6BngM+Fqja5mhvwUWRcStwLPAdxtcTzmzyA3N3EmuF/wdSfMbWlFy64GnI2Ki0YUksAH4q4hYAKwGvpf/jjerPwN+S9JR4LeAMaAmn3O9P4QxoLjHtSB/7gqSfgfYBqyNiPfrVNtUEtVcZA/QV9OKpleu3nnArwAvSBoFbgf2N3hStexnHBE/LfouPAH8ep1qKyXJd+IMsD8iLkbEW8Dr5MK+UWbyPV5P44dkIFnNXwb2AUTEj4Brye3h0ghJvsdnI+LzEdFDLuOIiNpMXNd5wmEWcJLcn3yFCYdPT2rTQ25SYkmjJkYqqHlJ0ePPAUPNXO+k9i/Q+AnVJJ/xLxc9/j3gUJPXuwr4bv7xDeT+XP+lZq453+4WYJT8NTAt8L34AXBv/vGnyI25N6T2hPXeAFyTf7wD2F6zehrwAawm14t5E9iWP7edXC8d4P8DPwGG8z/7m+BLVq7mbwPH8/U+P12YNkO9k9o2PNwTfsaP5j/jl/Kf8S1NXq/IDX+9AhwD1jf7Z5w/fgjob3StM/icu4EX89+LYeB3m7ze/wK8kW/zBPChWtXiK1TNzDKomScezMysQg53M7MMcribmWWQw93MLIMc7mZmGeRwNzPLIIe7mVkGOdzNzDLo3wE597vc/OhwgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get weights and biases\n",
    "W1, b1, W2, b2,b3,W3 = model['W1'], model['b1'], model['W2'], model['b2'],model['b3'],model[\"W3\"]\n",
    "\n",
    "diffArray = []\n",
    "\n",
    "plotX = []\n",
    "plotY = []\n",
    "\n",
    "inputArr = []\n",
    "outputArr = []\n",
    "for i in range(len(test_data)-1):\n",
    "    _a0 = test_data[i]\n",
    "    #print(_a0, _a0[1]-_a0[0])\n",
    "    diffArray.append(_a0[1]-_a0[0])\n",
    "    inputArr.append(_a0[1])\n",
    "    _z1 = _a0.dot(W1) + b1\n",
    "    # Put it through the first activation function\n",
    "    _a1 = np.tanh(_z1)\n",
    "    # Second linear step\n",
    "    _z2 = _a1.dot(W2) + b2\n",
    "    # Second activation function\n",
    "    _a2 = np.tanh(_z2)\n",
    "    #Third linear step\n",
    "    _z3 = _a2.dot(W3) + b3\n",
    "    #For the Third linear activation function we use the softmax function, either the sigmoid of softmax should be used for the last layer\n",
    "    _a3 = softmax(_z3)\n",
    "    if(i<10):\n",
    "        print(_a3)\n",
    "    plotX.append(_a3[0][0])\n",
    "    plotY.append(_a3[0][1])\n",
    "plt.scatter(plotX, plotY)\n",
    "    # Calculate the point density\n",
    "#     xy = np.vstack([plotX,plotY])\n",
    "#     z = gaussian_kde(xy)(xy)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "#     plt.show()\n",
    "\n",
    "#plt.hist(diffArray, bins=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lost muons\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-24994748d6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate the point density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmuon_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmuonX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmuonY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmuon_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuon_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuon_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, bw_method)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mset_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36m_compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m             self._data_covariance = atleast_2d(np.cov(self.dataset, rowvar=1,\n\u001b[1;32m    509\u001b[0m                                                bias=False))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_inv_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_covariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0minv_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_lu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         raise ValueError('illegal value in %d-th argument of internal '\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "# plot muons, this doesn't work right now and we have no idea why\n",
    "muonX = [] # value of \"muon\" output node\n",
    "muonY = [] # value of \"electron\" output node\n",
    "mCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==1:\n",
    "        mCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y)or x<0 or y<0)!=True:\n",
    "            muonX.append(x)\n",
    "            muonY.append(y)\n",
    "print(mCount-len(muonX), \"lost muons\")\n",
    "# Calculate the point density\n",
    "muon_xy = np.vstack([muonX,muonY])\n",
    "muon_z = gaussian_kde(muon_xy)(muon_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(muonX, muonY, c=muon_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Muons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()\n",
    "#plt.scatter(muonX, muonY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot electrons\n",
    "eleX = [] # value of \"muon\" output node\n",
    "eleY = [] # value of \"electron\" output node\n",
    "eCount = 0\n",
    "for x, y, l in zip(plotX, plotY, test_labels):\n",
    "    if l[0]==0:\n",
    "        eCount +=1\n",
    "        if(np.isnan(x) or np.isnan(y) or np.isinf(x) or np.isinf(y) or x<0 or y<0)!=True:\n",
    "            eleX.append(x)\n",
    "            eleY.append(y)\n",
    "print(eCount-len(eleX), \"lost electrons\")\n",
    "# Calculate the point density\n",
    "ele_xy = np.vstack([eleX,eleY])\n",
    "ele_z = gaussian_kde(ele_xy)(ele_xy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(eleX, eleY, c=ele_z, s=100, edgecolor='')\n",
    "plt.title(\"Electron Node Value vs Muon Node Value for True Electrons\")\n",
    "plt.xlabel(\"Value of Muon Output Node\")\n",
    "plt.ylabel(\"Value of Electron Output Node\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffArr = []\n",
    "discardedVals = 0\n",
    "for x, y in zip(plotX, plotY):\n",
    "    if(abs(y-x)<.75):\n",
    "        diffArr.append(y-x)\n",
    "    else:\n",
    "        discardedVals += 1\n",
    "print(discardedVals, \"differences greater than .75\")\n",
    "plt.hist(diffArr, bins=1000)\n",
    "plt.title(\"Difference in Electron and Muon Output Node Values (E-M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some models with different numbers of epochs\n",
    "print(\"model 200\")\n",
    "model_200 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_200 = train(model_200,train_data,train_labels,learning_rate=0.01,epochs=201,print_loss=True)\n",
    "# model_300 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_300 = train(model_300,train_data,train_labels,learning_rate=0.01,epochs=301,print_loss=True)\n",
    "print(\"model 400\")\n",
    "model_400 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "model_400 = train(model_400,train_data,train_labels,learning_rate=0.01,epochs=401,print_loss=True)\n",
    "# model_500 = initialize_parameters(nn_input_dim=2, nn_hdim= 5, nn_output_dim= 2)\n",
    "# model_500 = train(model_500,train_data,train_labels,learning_rate=0.01,epochs=501,print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 200 accuracy: \", accuracyOfModel(model_200, test_data, test_labels))\n",
    "print(\"Model 400 accuracy: \", accuracyOfModel(model_400, test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
